---
categories:
- NUMBERS THAT DAZZLED THE WORLD
- ONE
- HISTORY
- MATHEMATICS
date: 2025-04-07
description: "This post is the first chapter of my upcoming book *Numbers That Dazzled the World* and it traces how humanity's simplest number shaped civilization, from prehistoric tally marks to Leibniz's binary code. Discover how $1$ birthed mathematics, writing, and modern computing."
image: one.png
title: "In the Beginning... There Was $1$!"
bibliography: references.bib
comments:
    giscus:
        repo: aelmokadem/aelmokadem
    #hypothesis: true
    #utterances:
    #    repo: aelmokadem/aelmokadem
draft: false
---

## How $1$ Built Civilization

When we consider the *Numbers that Dazzled the World*, our journey must inevitably begin with the most fundamental number of all---$1$. This singular digit holds a unique position in mathematics and human cognition. Why does $1$ deserve this privileged status rather than 2, 3, or any other number? The answer lies in its elemental nature---it is the atomic unit of counting, the irreducible foundation upon which all other numbers are built. Every act of enumeration, whether counting pages in a book, steps taken during a walk, or even atoms in the vast universe, begins with this most basic of numbers. In this profound sense, the history of $1$ is inextricably linked to the history of human thought itself, marking our species' cognitive awakening to the very concept of quantity and measurement [@kaplan2000nothing].

The roots of numerical understanding extend deep into our biological heritage. Extensive research has demonstrated that this quantitative awareness is not uniquely human---it appears throughout the animal kingdom. Controlled experiments have shown that diverse species possess this fundamental ability. Mice can be trained to perform a specific number of tasks to receive rewards, demonstrating their capacity for numerical discrimination. Chimpanzees have shown even more advanced capabilities, learning to match numeral symbols to corresponding quantities of bananas. Even our evolutionary cousins, the Neanderthals, displayed this basic numerical instinct. Archaeological evidence suggests they could clearly distinguish between single objects (one fruit), pairs (two fruits), and multiple items, showing the same foundational quantitative understanding that characterizes modern humans [@joseph2000history].

## The Bone That Changed Math 

What truly set humans apart was not this innate numerical sense, but rather our ability to transform it into systematic counting. This cognitive revolution occurred with the invention of tally sticks---carefully crafted bone artifacts bearing sequences of incised markings. These ancient tools represented a quantum leap in human thinking. Unlike other animals limited to immediate quantity recognition in their environment, these physical counting devices enabled prehistoric humans to record, track, and manipulate numbers beyond the present moment. They could now keep count over time, compare quantities from different occasions, and even perform basic operations. This breakthrough laid the essential foundation for all subsequent mathematical development, establishing the mental framework that would eventually lead to modern mathematics [@joseph2000history].

Among the most fascinating of these ancient counting tools is the Ishango Bone, discovered in 1960 in what is now the Democratic Republic of Congo. This remarkable artifact, dating back approximately 20,000 years BCE [@ifrah2000universal], consists of a baboon's fibula bearing a series of carefully made markings arranged in distinct columns. While scholars continue to debate its exact purpose---with theories ranging from tracking lunar cycles to recording hunting yields or seasonal changes---what remains undeniable is that each incision systematically represents the concept of "one," with groupings of these marks representing larger quantities. This demonstrates an early understanding of one-to-one correspondence, a fundamental mathematical principle.

The Ishango Bone was not an isolated development. Archaeologists have discovered even older tally sticks that push back the origins of human counting. A notable example comes from Swaziland, dating to about 37,000 years BCE, while another significant specimen was found in Czechoslovakia, originating from approximately 32,000 years BCE. What makes the Ishango Bone particularly noteworthy among these ancient artifacts are the specific numerical patterns evident in its markings. The bone displays groupings of marks that correspond to the numbers 11, 13, 17, and 19---which happen to be precisely the prime numbers between 10 and 20. These special numbers, divisible only by themselves and $1$, hold a unique position in mathematics as the fundamental building blocks of all natural numbers through multiplication. The apparent organization of these primes on the Ishango Bone suggests its creators may have recognized these numerical relationships, implying a surprisingly advanced understanding of mathematical concepts for such an early period. However, this interpretation remains controversial in the scientific community, with many researchers maintaining that these prime number groupings could simply be coincidental [@deheinzelin1957ishango]. This ongoing debate highlights both the sophistication of early human cognition and the challenges inherent in interpreting ancient artifacts through modern mathematical frameworks.

## From Clay Tokens to Computers 

The next major revolution in numerical thinking came with the Sumerians of Mesopotamia, who achieved a profound conceptual breakthrough by liberating $1$ from physical tally marks. Their ingenious innovation took the form of small clay cones, each representing an abstract unit of "one" [@burton2010history]. This development marked humanity's first step toward truly symbolic mathematics---no longer requiring physical marks or notches, a single clay token could now represent any single quantity. This abstraction allowed for much more flexible and powerful mathematical operations.

These portable clay tokens enabled far more than simple counting---they made possible genuine calculation. Archaeological evidence clearly shows that the Sumerians used these tokens to perform the earliest known addition and subtraction operations in human history. This raises a fundamental question about the origins of mathematics: why did this systematic numerical thinking emerge in Sumerian society when many other cultures, such as certain isolated tribes in the Amazon and Australia, have existed for millennia with only the most basic numerical concepts---often just words for "one" and "many"---and no developed mathematics? The answer appears to lie in the revolutionary development of urban civilization. As the world's first cities grew in Mesopotamia, they created unprecedented social and economic complexities---the need to track commercial transactions between citizens, calculate agricultural yields, manage storage surpluses, and administer taxes. These urban challenges demanded precise accounting methods that went far beyond simple counting, providing the practical impetus for the development of true mathematics [@kaplan2000nothing].

The impact of $1$ on the development of civilization extended even further when it became the unexpected catalyst for one of humanity's most important inventions---writing. The story of this development again begins with the Sumerians and their counting tokens. Merchants and officials would keep their valuable clay cones in sealed clay bowls for safekeeping, but faced an obvious problem: once sealed, they couldn't verify the contents without breaking the seal. Their solution was to mark the exterior of the bowls with symbols representing the tokens inside. Over time, they realized the tokens themselves became unnecessary---the exterior markings alone could convey the information. This realization led to the development of cuneiform writing, making $1$ not just the foundation of mathematics but also a key player in the origin of written communication [@ifrah2000universal].

The ancient Egyptians developed their own revolutionary application of $1$ that enabled their architectural marvels. While the Sumerians used $1$ conceptually, the Egyptians implemented it physically through standardized measurement. Their "royal cubit"---a precisely measured rod equal to the length from elbow to fingertips plus the width of a palm [@menninger1992number]---became the fundamental unit underlying their monumental architecture. This consistent use of $1$ as a fixed measurement standard allowed the precise engineering evident in the pyramids and temples that continue to awe us today. The Egyptians guarded this standard carefully, maintaining official copies in temples and ensuring its consistent use throughout their kingdom.

The Greek mathematician and philosopher Pythagoras[^101] elevated $1$ from a practical tool to a metaphysical concept. In his philosophical system, $1$ became the monad---the fundamental substance from which all existence flows. His famous declaration that "All is number" reflected his belief in the primacy of numerical relationships in understanding reality. Since all natural numbers are ultimately composed of units of $1$, Pythagoras saw it as the essential building block of both mathematics and the universe itself [@burton2010history]. This philosophical conception marked a new chapter in humanity's relationship with numbers, elevating mathematics from practical tool to intellectual pursuit.

The development of the Indian numeral system represented both a democratization and temporary diminishment of $1$'s singular status. This revolutionary system, which we still use today, made $1$ one digit among nine others (1-9), later joined by the equally important $0$. While this might seem to reduce $1$'s importance, in reality it allowed for far more powerful mathematical operations. The Indian system enabled calculations with previously unimaginable efficiency, leading to breakthroughs in astronomy---including the realization that Earth rotates on its axis and revolves around the sun, a discovery made nearly a thousand years before Copernicus[^102] [@seife2000zero]. Indian mathematicians also achieved remarkably accurate calculations of Earth's diameter. These advances were only possible through the collaborative power of $1$ working in concert with its numerical companions.

The transmission of Indian mathematics to the Arab world through scholars like Al-Biruni[^103] [@joseph2000history] and Al-Khwarizmi[^104] [@ifrah2000universal] led to further developments, most notably the establishment of algebra as a formal mathematical discipline [@burton2010history]. When these numerical concepts finally reached Europe, they fueled scientific revolutions---including the confirmation of Earth's motion around the sun and the development of classical physics [@kaplan2000nothing]. 

The restoration of $1$'s special status owes much to Gottfried Leibniz,[^105] the German mathematician who co-founded calculus with Newton[^106] [@burton2010history]. A philosopher as well as mathematician, Leibniz viewed conventional language as inherently flawed—--prone to human error and logical inconsistency. He championed mathematics as the only truly universal language, proposing its use for expressing all rational thought. Though this radical idea initially met with scientific indifference (leading Leibniz to temporarily abandon it), he later found validation in the ancient Chinese *I Ching*. This text's depiction of cosmic evolution through opposing dualities—--day and night, male and female---resonated deeply with his thinking [@strickland2022binary], reinforcing his conviction that logic could be reduced to binary states.

This philosophical breakthrough led Leibniz to develop the binary system using only $1$ and $0$, a stark contrast to the decimal system's ten digits. Remarkably, this minimal pair could represent any number. The decimal representation of 12 uses place values where one container represents ones (holding 2) and another represents tens (holding 1), combining to make $10 + 2 = 12$. 

The binary system works differently through powers of two. Four containers represent, from right to left: 2$^0$ (1), 2$^1$ (2), 2$^2$ (4), and 2$^3$ (8). To represent 12, we place one ball in the 8-container, one in the 4-container, and leave the others empty, giving $8 + 4 + 0 + 0 = 12$, which translates to 1100 in binary notation.

Leibniz recognized this system's potential for mechanical computation. While he successfully built a decimal calculator, the binary version remained unrealized in his lifetime---a challenge beyond seventeenth-century engineering capabilities [@strickland2022binary].

In his later years, Leibniz attributed almost mystical significance to the binary system. He saw $1$ as representing divine unity or existence itself, while $0$ symbolized nothingness---the interaction between them mirroring the process of creation [@strickland2022binary]. While this metaphysical interpretation may seem fanciful, Leibniz's practical insights about binary mathematics proved extraordinarily prescient.

Today, binary code has become the fundamental language underpinning our digital world, exactly as Leibniz foresaw. The simple dichotomy of $1$ and $0$ now encodes everything from financial transactions to personal communications, from scientific data to entertainment media. As we contemplate the possibility that other numerical systems may fade into obsolescence, we witness the ultimate triumph of $1$---the number that marked humanity's first steps into mathematics now stands poised to dominate our digital future. From ancient tally marks to quantum bits, the journey of $1$ reflects nothing less than the evolution of human thought itself [@strickland2022binary].

<!-- footnotes -->

[^101]: Pythagoras (c. 570-495 BCE) was a Greek mathematician and philosopher who had a great influence on Greek and world mathematics and philosophy. His name is associated with one of the most famous mathematical theories of all time, the Pythagorean theorem [@britannica2023pythagoras].

[^102]: Nicolaus Copernicus (1473-1543) was born in the Kingdom of Poland and is one of the most important figures of the European Renaissance. He is credited with having gone against the geocentric model of the universe and replacing it with the heliocentric model [@britannica2023copernicus].

[^103]: Abu al-Rayhan Muhammad ibn Ahmad al-Biruni (973-1048) was born in Khwarazm, a historic region located in Central Asia. He made significant contributions to mathematics, astronomy, and geography, making him one of the most important Islamic polymath scholars [@britannica2023biruni].

[^104]: Abu Abdullah Muhammad ibn Musa al-Khwarizmi (c. 780–c. 850) is also from Khwarazm and is one of the most famous Muslim scholars. He is renowned for laying the foundations of algebra [@britannica2023khwarizmi].

[^105]: Gottfried Wilhelm Leibniz (1646-1716) was a German mathematician and philosopher who made many contributions in both fields, the most famous of which was the invention of calculus. Isaac Newton, who also developed calculus, accused Leibniz of plagiarizing his discovery, a charge that remained controversial, but later mathematicians recognized the differences between their versions [@britannica2023leibniz].

[^106]: Isaac Newton (1642-1727) was perhaps the most famous physicist and mathematician of all time and one of the pioneers of the scientific revolution in Europe. He held the presidency of the British Royal Society and made numerous contributions, including the development of calculus with Leibniz and the formulation of the laws of motion and gravity [@britannica2023newton].
